{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cd7159d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/site-packages (0.22.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: torch==2.7.0 in /usr/local/lib/python3.12/site-packages (from torchvision) (2.7.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (80.7.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (3.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.7.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/site-packages (from jinja2->torch==2.7.0->torchvision) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfaf56d",
   "metadata": {},
   "source": [
    "On commence par importer les bibliothèques nécessaires pour notre projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7272fffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # bibliothèque principale pour les réseaux de neurones\n",
    "import torch.nn as nn  # pour créer les couches de notre réseau\n",
    "import torch.optim as optim  # pour les algorithmes d’optimisation (ex: SGD)\n",
    "from torchvision import datasets, transforms  # pour charger MNIST et transformer les images\n",
    "from torch.utils.data import DataLoader  # pour charger les données en batchs\n",
    "\n",
    "import numpy as np  # utilisé pour les calculs en LDP\n",
    "import random  # pour la reproductibilité\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb877526",
   "metadata": {},
   "source": [
    "On définit les paramètres globaux de notre simulation d'apprentissage fédéré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "917519d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 10  # nombre de clients qui participent à l'apprentissage\n",
    "BATCH_SIZE = 64  # taille des lots de données envoyés à chaque étape\n",
    "EPOCHS = 3  # nombre de \"rounds\" fédérés (synchronisations globales)\n",
    "LOCAL_EPOCHS = 2  # nombre d'epochs effectués localement sur chaque client\n",
    "LEARNING_RATE = 0.01  # taux d'apprentissage du modèle\n",
    "EPSILON = 10  # paramètre epsilon de la confidentialité différentielle (plus il est petit, plus la vie privée est protégée)\n",
    "R = 0.075  # amplitude max de perturbation pour le bruit local\n",
    "\n",
    "epsilon_list = [1,10,20,50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3b7508",
   "metadata": {},
   "source": [
    "La cellule suivante permet que chaque exécution donne les mêmes résultats (utile pour tester ou déboguer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a903304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ff89cc",
   "metadata": {},
   "source": [
    "Avant de créer notre modèle, on charge les données MNIST, qui sont des images de chiffres manuscrits. On applique quelques transformations, puis on divise les données entre les clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9375343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On définit une transformation pour transformer les images en tenseurs et les normaliser\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])  # conversion image PIL → tenseur PyTorch + centrage et réduction des pixels\n",
    "\n",
    "# Chargement des données d'entraînement MNIST\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# On divise les données d'entraînement en 10 parts égales : une pour chaque client\n",
    "client_datasets = torch.utils.data.random_split(mnist_train,[len(mnist_train)//NUM_CLIENTS]*NUM_CLIENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f40253b",
   "metadata": {},
   "source": [
    "On cherche maintenant à définir un modèle CNN efficace pour classer les chiffres manuscrits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bc8c13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # 1 canal → 32\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 32 → 64\n",
    "        self.pool = nn.MaxPool2d(2)  # réduit la taille de moitié\n",
    "        self.dropout = nn.Dropout(0.25)  # évite le sur-apprentissage\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # couche dense intermédiaire\n",
    "        self.fc2 = nn.Linear(128, 10)  # couche finale (10 classes pour les chiffres)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))  # conv1 + relu + pooling\n",
    "        x = self.pool(torch.relu(self.conv2(x)))  # conv2 + relu + pooling\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, 64 * 7 * 7)  # aplatissement avant la couche fully connected\n",
    "        x = torch.relu(self.fc1(x))  # couche dense + relu\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)  # pas de softmax ici (géré par la fonction de perte)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0e0f15",
   "metadata": {},
   "source": [
    "Afin d'ajouter la partie confidentialité différentielle locale (LDP), permettant à chaque client d'ajouter du bruit à ses poids avant de les envoyer pour protéger ses données, on va maintenant implémenter une fonction ldp_perturb qui applique une perturbation à un poids individuel selon le mécanisme LDP et une autre perturb_model qui permet d'appliquer la perturbation à tout le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afa0fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ldp_perturb(w, c, r, epsilon):\n",
    "    # Équation (2) de l'article\n",
    "    p = ((w - c) * (np.exp(epsilon) - 1) + r * (np.exp(epsilon) + 1)) / (2 * r * (np.exp(epsilon) + 1))\n",
    "    \n",
    "    if np.random.rand() < p:\n",
    "        return c + r * (np.exp(epsilon) + 1) / (np.exp(epsilon) - 1)\n",
    "    else:\n",
    "        return c - r * (np.exp(epsilon) + 1) / (np.exp(epsilon) - 1)\n",
    "\n",
    "def perturb_model(model, c=0.0, r=R, epsilon=EPSILON):\n",
    "    with torch.no_grad():  # pas de calcul de gradient ici\n",
    "        for param in model.parameters():\n",
    "            w_np = param.view(-1).cpu().numpy()  # on met les poids sous forme de tableau\n",
    "            perturbed = np.array([ldp_perturb(wi, c, r, epsilon) for wi in w_np])  # on applique la perturbation à chaque poids\n",
    "            param.copy_(torch.tensor(perturbed).view_as(param))  # on remet les poids perturbés dans le modèle\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d05624c",
   "metadata": {},
   "source": [
    "Ci-dessous on implémente la fonction principale de l’apprentissage fédéré : chaque client s'entraîne localement, puis on agrège les modèles. On peut activer ou non la perturbation LDP pour ensuite comparer les résultats d'accuracy obtenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aac46c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def federated_learning(epsilone, apply_ldp=False):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # on utilise le GPU si dispo\n",
    "    global_model = CNN().to(device)  # modèle global partagé\n",
    "    criterion = nn.CrossEntropyLoss()  # fonction de perte pour la classification\n",
    "\n",
    "    for round in range(EPOCHS):\n",
    "        print(f\"\\nRound {round + 1}\")\n",
    "        client_models = []\n",
    "\n",
    "        for client_id in range(NUM_CLIENTS):\n",
    "            print(f\"  Training Client {client_id + 1}/{NUM_CLIENTS}\", end=\"\\r\")\n",
    "\n",
    "            # Chaque client commence avec le modèle global\n",
    "            client_model = CNN().to(device)\n",
    "            client_model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "            optimizer = optim.SGD(client_model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "            train_loader = DataLoader(client_datasets[client_id], batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "            # Entraînement local\n",
    "            client_model.train()\n",
    "            for epoch in range(LOCAL_EPOCHS):\n",
    "                for data, target in train_loader:\n",
    "                    data, target = data.to(device), target.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    output = client_model(data)\n",
    "                    loss = criterion(output, target)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            # On applique LDP si demandé\n",
    "            if apply_ldp:\n",
    "                perturb_model(client_model, r=R, epsilon=epsilone)\n",
    "\n",
    "            client_models.append(client_model.state_dict())  # on sauvegarde les poids\n",
    "\n",
    "        # Agrégation : moyenne des poids de tous les clients\n",
    "        new_state_dict = global_model.state_dict()\n",
    "        for key in new_state_dict:\n",
    "            new_state_dict[key] = torch.stack([client_model[key] for client_model in client_models], 0).mean(0)\n",
    "        global_model.load_state_dict(new_state_dict)\n",
    "\n",
    "        # Évaluation du modèle global après chaque round\n",
    "        evaluate_model(global_model, device, f\"Round {round + 1}\")\n",
    "\n",
    "    return global_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30c2c29",
   "metadata": {},
   "source": [
    "Il reste à implémenter une fonction evaluate_model qui évalue le modèle global."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce97b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, device, stage=\"Final\"):\n",
    "    model.eval()  # mode évaluation\n",
    "    test_loader = DataLoader(datasets.MNIST(root='./data', train=False, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])), batch_size=1000)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)  # on prend la classe avec la plus grande probabilité\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"{stage} Test Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41c8331e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FL avec LDP en cours...\n",
      "\n",
      "Round 1\n",
      "Round 1 Test Accuracy: 93.56%\n",
      "\n",
      "Round 2\n",
      "Round 2 Test Accuracy: 95.57%\n",
      "\n",
      "Round 3\n",
      "Round 3 Test Accuracy: 96.52%\n",
      "\n",
      "Evaluation:\n",
      "Final Test Accuracy: 96.52%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "96.52"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lancement de l'entraînement fédéré avec perturbation LDP\n",
    "\n",
    "print(\"FL avec LDP en cours...\")\n",
    "model_with_ldp = federated_learning(2, apply_ldp=True)\n",
    "print(\"\\nEvaluation:\")\n",
    "evaluate_model(model_with_ldp, torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "859cfb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Round 1\n",
      "  Training Client 1/10\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 Test Accuracy: 84.94%\n",
      "\n",
      "Round 2\n",
      "Round 2 Test Accuracy: 93.38%\n",
      "\n",
      "Round 3\n",
      "Round 3 Test Accuracy: 94.88%\n",
      "\n",
      "Round 1\n",
      "Round 1 Test Accuracy: 89.76%\n",
      "\n",
      "Round 2\n",
      "Round 2 Test Accuracy: 96.27%\n",
      "\n",
      "Round 3\n",
      "Round 3 Test Accuracy: 97.07%\n",
      "\n",
      "Round 1\n",
      "Round 1 Test Accuracy: 93.11%\n",
      "\n",
      "Round 2\n",
      "Round 2 Test Accuracy: 96.12%\n",
      "\n",
      "Round 3\n",
      "Round 3 Test Accuracy: 96.65%\n",
      "\n",
      "Round 1\n",
      "Round 1 Test Accuracy: 94.32%\n",
      "\n",
      "Round 2\n",
      "Round 2 Test Accuracy: 96.38%\n",
      "\n",
      "Round 3\n",
      "Round 3 Test Accuracy: 96.85%\n",
      "\n",
      "Evaluation:\n",
      "Final Test Accuracy: 94.88%\n",
      "\n",
      "Evaluation:\n",
      "Final Test Accuracy: 97.07%\n",
      "\n",
      "Evaluation:\n",
      "Final Test Accuracy: 96.65%\n",
      "\n",
      "Evaluation:\n",
      "Final Test Accuracy: 96.85%\n"
     ]
    }
   ],
   "source": [
    "liste = []\n",
    "for epsilone in epsilon_list : \n",
    "    model_with_ldp = federated_learning(epsilone, apply_ldp=True)\n",
    "    liste.append(model_with_ldp)\n",
    "\n",
    "for element in liste :\n",
    "    print(\"\\nEvaluation:\")\n",
    "    evaluate_model(element, torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
