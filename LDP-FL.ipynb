{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cd7159d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.22.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/site-packages (from torchvision) (2.2.6)\n",
      "Collecting torch==2.7.0 (from torchvision)\n",
      "  Downloading torch-2.7.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/site-packages (from torchvision) (11.2.1)\n",
      "Collecting filelock (from torch==2.7.0->torchvision)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (80.7.1)\n",
      "Collecting sympy>=1.13.3 (from torch==2.7.0->torchvision)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch==2.7.0->torchvision)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch==2.7.0->torchvision)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch==2.7.0->torchvision)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch==2.7.0->torchvision)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch==2.7.0->torchvision)\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch==2.7.0->torchvision)\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch==2.7.0->torchvision)\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch==2.7.0->torchvision)\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch==2.7.0->torchvision)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch==2.7.0->torchvision)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch==2.7.0->torchvision)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch==2.7.0->torchvision)\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch==2.7.0->torchvision)\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch==2.7.0->torchvision)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch==2.7.0->torchvision)\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.0 (from torch==2.7.0->torchvision)\n",
      "  Downloading triton-3.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch==2.7.0->torchvision)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/site-packages (from jinja2->torch==2.7.0->torchvision) (3.0.2)\n",
      "Downloading torchvision-0.22.0-cp312-cp312-manylinux_2_28_x86_64.whl (7.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.7.0-cp312-cp312-manylinux_2_28_x86_64.whl (865.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.0/865.0 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/21\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.26.5━━━━━━━━━━\u001b[0m \u001b[32m 6/21\u001b[0m [nvidia-nccl-cu12]]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.26.5:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/21\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.26.5━━━━━━━━━━━━\u001b[0m \u001b[32m 6/21\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/21\u001b[0m [torchvision]\u001b[0m [torchvision]ver-cu12]2]\n",
      "\u001b[1A\u001b[2KSuccessfully installed filelock-3.18.0 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.0 torchvision-0.22.0 triton-3.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfaf56d",
   "metadata": {},
   "source": [
    "On commence par importer les bibliothèques nécessaires pour notre projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7272fffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # bibliothèque principale pour les réseaux de neurones\n",
    "import torch.nn as nn  # pour créer les couches de notre réseau\n",
    "import torch.optim as optim  # pour les algorithmes d’optimisation (ex: SGD)\n",
    "from torchvision import datasets, transforms  # pour charger MNIST et transformer les images\n",
    "from torch.utils.data import DataLoader  # pour charger les données en batchs\n",
    "\n",
    "import numpy as np  # utilisé pour les calculs en LDP\n",
    "import random  # pour la reproductibilité\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb877526",
   "metadata": {},
   "source": [
    "On définit les paramètres globaux de notre simulation d'apprentissage fédéré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "917519d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 10  # nombre de clients qui participent à l'apprentissage\n",
    "BATCH_SIZE = 64  # taille des lots de données envoyés à chaque étape\n",
    "EPOCHS = 3  # nombre de \"rounds\" fédérés (synchronisations globales)\n",
    "LOCAL_EPOCHS = 2  # nombre d'epochs effectués localement sur chaque client\n",
    "LEARNING_RATE = 0.01  # taux d'apprentissage du modèle\n",
    "EPSILON = 10  # paramètre epsilon de la confidentialité différentielle (plus il est petit, plus la vie privée est protégée)\n",
    "R = 0.075  # amplitude max de perturbation pour le bruit local\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3b7508",
   "metadata": {},
   "source": [
    "La cellule suivante permet que chaque exécution donne les mêmes résultats (utile pour tester ou déboguer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a903304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ff89cc",
   "metadata": {},
   "source": [
    "Avant de créer notre modèle, on charge les données MNIST, qui sont des images de chiffres manuscrits. On applique quelques transformations, puis on divise les données entre les clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9375343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On définit une transformation pour transformer les images en tenseurs et les normaliser\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])  # conversion image PIL → tenseur PyTorch + centrage et réduction des pixels\n",
    "\n",
    "# Chargement des données d'entraînement MNIST\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# On divise les données d'entraînement en 10 parts égales : une pour chaque client\n",
    "client_datasets = torch.utils.data.random_split(mnist_train,[len(mnist_train)//NUM_CLIENTS]*NUM_CLIENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f40253b",
   "metadata": {},
   "source": [
    "On cherche maintenant à définir un modèle CNN efficace pour classer les chiffres manuscrits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bc8c13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # 1 canal → 32\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 32 → 64\n",
    "        self.pool = nn.MaxPool2d(2)  # réduit la taille de moitié\n",
    "        self.dropout = nn.Dropout(0.25)  # évite le sur-apprentissage\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # couche dense intermédiaire\n",
    "        self.fc2 = nn.Linear(128, 10)  # couche finale (10 classes pour les chiffres)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))  # conv1 + relu + pooling\n",
    "        x = self.pool(torch.relu(self.conv2(x)))  # conv2 + relu + pooling\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, 64 * 7 * 7)  # aplatissement avant la couche fully connected\n",
    "        x = torch.relu(self.fc1(x))  # couche dense + relu\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)  # pas de softmax ici (géré par la fonction de perte)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0e0f15",
   "metadata": {},
   "source": [
    "Afin d'ajouter la partie confidentialité différentielle locale (LDP), permettant à chaque client d'ajouter du bruit à ses poids avant de les envoyer pour protéger ses données, on va maintenant implémenter une fonction ldp_perturb qui applique une perturbation à un poids individuel selon le mécanisme LDP et une autre perturb_model qui permet d'appliquer la perturbation à tout le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afa0fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ldp_perturb(w, c, r, epsilon):\n",
    "    # Calcule la probabilité de choisir +r ou -r\n",
    "    p = ((w - c) * (np.exp(epsilon) - 1) + r * (np.exp(epsilon) + 1)) / (2 * r * (np.exp(epsilon) + 1))\n",
    "    if np.random.rand() < p:\n",
    "        return c + r * (np.exp(epsilon) + 1) / (np.exp(epsilon) - 1)\n",
    "    else:\n",
    "        return c - r * (np.exp(epsilon) + 1) / (np.exp(epsilon) - 1)\n",
    "\n",
    "def perturb_model(model, c=0.0, r=R, epsilon=EPSILON):\n",
    "    with torch.no_grad():  # pas de calcul de gradient ici\n",
    "        for param in model.parameters():\n",
    "            w_np = param.view(-1).cpu().numpy()  # on met les poids sous forme de tableau\n",
    "            perturbed = np.array([ldp_perturb(wi, c, r, epsilon) for wi in w_np])  # on applique la perturbation à chaque poids\n",
    "            param.copy_(torch.tensor(perturbed).view_as(param))  # on remet les poids perturbés dans le modèle\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d05624c",
   "metadata": {},
   "source": [
    "Ci-dessous on implémente la fonction principale de l’apprentissage fédéré : chaque client s'entraîne localement, puis on agrège les modèles. On peut activer ou non la perturbation LDP pour ensuite comparer les résultats d'accuracy obtenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aac46c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def federated_learning(apply_ldp=False):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # on utilise le GPU si dispo\n",
    "    global_model = CNN().to(device)  # modèle global partagé\n",
    "    criterion = nn.CrossEntropyLoss()  # fonction de perte pour la classification\n",
    "\n",
    "    for round in range(EPOCHS):\n",
    "        print(f\"\\nRound {round + 1}\")\n",
    "        client_models = []\n",
    "\n",
    "        for client_id in range(NUM_CLIENTS):\n",
    "            print(f\"  Training Client {client_id + 1}/{NUM_CLIENTS}\", end=\"\\r\")\n",
    "\n",
    "            # Chaque client commence avec le modèle global\n",
    "            client_model = CNN().to(device)\n",
    "            client_model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "            optimizer = optim.SGD(client_model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "            train_loader = DataLoader(client_datasets[client_id], batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "            # Entraînement local\n",
    "            client_model.train()\n",
    "            for epoch in range(LOCAL_EPOCHS):\n",
    "                for data, target in train_loader:\n",
    "                    data, target = data.to(device), target.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    output = client_model(data)\n",
    "                    loss = criterion(output, target)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            # On applique LDP si demandé\n",
    "            if apply_ldp:\n",
    "                perturb_model(client_model, r=R, epsilon=EPSILON)\n",
    "\n",
    "            client_models.append(client_model.state_dict())  # on sauvegarde les poids\n",
    "\n",
    "        # Agrégation : moyenne des poids de tous les clients\n",
    "        new_state_dict = global_model.state_dict()\n",
    "        for key in new_state_dict:\n",
    "            new_state_dict[key] = torch.stack([client_model[key] for client_model in client_models], 0).mean(0)\n",
    "        global_model.load_state_dict(new_state_dict)\n",
    "\n",
    "        # Évaluation du modèle global après chaque round\n",
    "        evaluate_model(global_model, device, f\"Round {round + 1}\")\n",
    "\n",
    "    return global_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30c2c29",
   "metadata": {},
   "source": [
    "Il reste à implémenter une fonction evaluate_model qui évalue le modèle global."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce97b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, device, stage=\"Final\"):\n",
    "    model.eval()  # mode évaluation\n",
    "    test_loader = DataLoader(datasets.MNIST(root='./data', train=False, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])), batch_size=1000)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)  # on prend la classe avec la plus grande probabilité\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"{stage} Test Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41c8331e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FL avec LDP en cours...\n",
      "\n",
      "Round 1\n",
      "Round 1 Test Accuracy: 94.65%\n",
      "\n",
      "Round 2\n",
      "Round 2 Test Accuracy: 96.13%\n",
      "\n",
      "Round 3\n",
      "Round 3 Test Accuracy: 96.84%\n",
      "\n",
      "Evaluation:\n",
      "Final Test Accuracy: 96.84%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "96.84"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lancement de l'entraînement fédéré avec perturbation LDP\n",
    "\n",
    "print(\"FL avec LDP en cours...\")\n",
    "model_with_ldp = federated_learning(apply_ldp=True)\n",
    "print(\"\\nEvaluation:\")\n",
    "evaluate_model(model_with_ldp, torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
